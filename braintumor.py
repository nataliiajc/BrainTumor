# -*- coding: utf-8 -*-
"""BrainTumor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MBqD4e80xUDKiHJaLoTltZ4qNmBEWum5

# Importaciones
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import os
import zipfile
from keras.applications.inception_v3 import InceptionV3, preprocess_input
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from pathlib import Path
#https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
#https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset

"""# Proceso

1. Subimos zip data set con directorios con nombre de clases
2. Extraemos data set y hacemos etiquetado
3. Creamos modelo
4. Entrenamos modelo

# ObtenciÃ³n de datos del ZIP
"""

file_name = "brain.zip"
general_dir = os.path.join(os.getcwd(),'brain')
zip_ref = zipfile.ZipFile(file_name,'r')
zip_ref.extractall(general_dir)
zip_ref.close()
print(general_dir)

IMG_SIZE = (150,150)
train_dir = Path(general_dir + "/Training")
test_dir = Path(general_dir + "/Testing")
print("Training_dir", train_dir)
print("Testing_dir", test_dir)

base_model = InceptionV3(input_shape = (150,150,3),
                         weights='imagenet',
                         include_top = False)

for layer in base_model.layers:
  layer.trainable = False

import keras

x = tf.keras.layers.Flatten()(base_model.layers[-1].output)
x = tf.keras.layers.Dense(1024, activation = 'relu')(x)
outputs = tf.keras.layers.Dense(4, activation='softmax')(x)

model = tf.keras.Model(inputs = base_model.inputs,outputs = outputs)

model.summary()

model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

datagen = ImageDataGenerator(rescale = 1.0/255.)
classes = ['glioma','meningioma','notumor','pituitary']

train_generator = datagen.flow_from_directory(train_dir,
                                              class_mode='categorical',
                                              target_size = (150,150)
                                              )

validation_generator = datagen.flow_from_directory(test_dir,
                                                     class_mode='categorical',
                                                     target_size = (150,150)
                                                   )

STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,logs={}):
    if (logs.get('accuracy')>0.990):
      print("Reached accuracy")
      self.model.stop_training = True

callbacks = myCallback()

history = model.fit(
    train_generator,
    validation_data = validation_generator,
    steps_per_epoch =100,
    epochs = 100,
    validation_steps = 50,
    verbose = 2,
    callbacks = [callbacks]
)

from sys import path_hooks
import os
import tensorflow as tf
from google.colab import files
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# @title  { form-width: "50px", display-mode: "both" }
img_path_gli = "/content/brain/Testing/glioma/Te-glTr_0000.jpg" # @param {type:"string"}
img_path_men = "/content/brain/Testing/meningioma/Te-meTr_0000.jpg"
img_path_non = "/content/brain/Testing/notumor/Te-noTr_0000.jpg"
img_path_pit = "/content/brain/Testing/pituitary/Te-piTr_0000.jpg"
img = mpimg.imread(img_path_gli)
plt.imshow(img)
plt.show()

from PIL import Image
img_2 = Image.open(img_path_men)
img_2 = img_2.resize((150,150))
plt.imshow(img_2)
plt.show()
img_2=np.expand_dims(img_2,axis=0)
model.predict_on_batch(img_2)

from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions
img = tf.keras.utils.load_img(img_path_non, target_size=(150, 150))
x = tf.keras.utils.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
# decode the results into a list of tuples (class, description, probability)
# (one such list for each sample in the batch)
print(preds)

from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions
img = tf.keras.utils.load_img(img_path_pit, target_size=(150, 150))
x = tf.keras.utils.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
# decode the results into a list of tuples (class, description, probability)
# (one such list for each sample in the batch)
print(preds)

from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions

from PIL import Image
img_1 = Image.open(img_path_pit)
img_1 = img_1.resize((150,150))
plt.imshow(img_1)
plt.show()

img = tf.keras.utils.load_img(img_path_pit, target_size=(150, 150))
x = tf.keras.utils.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
print(preds)
max = (tf.math.reduce_max(preds))
print(max)
index = 0
result = 0
for value in preds[0]:
  if (value == max):
    result = index
  index +=1
print(classes[result])

# Creation of a new directory
!mkdir -p models

model.save('/content/models/brain_model')

new_model = tf.keras.models.load_model('/content/models/brain_model')

# Check its architecture
new_model.summary()
new_model.evaluate(validation_generator)

files.download('/content/models/brain_model')

c=0
for i in os.listdir('/content/models/brain_model') :
 c+=1
 print(i,c)
 files.download('/content/models/brain_model/'+i)

files.download('/content/models/brain_model/variables')

model.save('models/h5model.h5')

# Recreate the exact same model, including its weights and the optimizer
new_model = tf.keras.models.load_model('models/h5model.h5')

# Show the model architecture
new_model.summary()

from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions

from PIL import Image
img_1 = Image.open(img_path_pit)
img_1 = img_1.resize((150,150))
plt.imshow(img_1)
plt.show()

img = tf.keras.utils.load_img(img_path_pit, target_size=(150, 150))
x = tf.keras.utils.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = new_model.predict(x)
print(preds)
max = (tf.math.reduce_max(preds))
print(max)
index = 0
result = 0
for value in preds[0]:
  if (value == max):
    result = index
  index +=1
print(classes[result])

files.download('/content/models/brain_model/variables/variables.data-00000-of-00001')

model.save_weights()

print("hola")

files.download('/content/models/h5model.h5')

!tar -czvf model.tar.gz models/brain_model

files.download('model.tar.gz')

model.save_weights('modelweights')

files.download('/content/modelweights.data-00000-of-00001')

from google.colab import drive
drive.mount('/content/gdrive')